{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luiznery/anaconda3/envs/fake/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "from liwc import Liwc\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_325013/152710845.py:1: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  filepaths = yaml.load(open(\"/home/luiznery/locus/dissertation/config/filepaths.yaml\"))\n"
     ]
    }
   ],
   "source": [
    "filepaths = yaml.load(open(\"/home/luiznery/locus/dissertation/config/filepaths.yaml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(filepaths['utils'])\n",
    "import data as data_loader\n",
    "import liwc_utils\n",
    "import vocab_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>perspective_score</th>\n",
       "      <th>flair_score</th>\n",
       "      <th>textblob_score</th>\n",
       "      <th>vader_score</th>\n",
       "      <th>detoxify_original_score</th>\n",
       "      <th>detoxify_unbiased_score</th>\n",
       "      <th>detoxify_multilingual_score</th>\n",
       "      <th>has_swearing</th>\n",
       "      <th>file</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user wat r u doin boy</td>\n",
       "      <td>0.037538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048113</td>\n",
       "      <td>0.014581</td>\n",
       "      <td>0.146005</td>\n",
       "      <td>False</td>\n",
       "      <td>aa_112.csv</td>\n",
       "      <td>aa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     text  perspective_score  flair_score  textblob_score  \\\n",
       "0  @user wat r u doin boy           0.037538          0.0             0.0   \n",
       "\n",
       "   vader_score  detoxify_original_score  detoxify_unbiased_score  \\\n",
       "0          0.0                 0.048113                 0.014581   \n",
       "\n",
       "   detoxify_multilingual_score  has_swearing        file group  \n",
       "0                     0.146005         False  aa_112.csv    aa  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET = 'twitter' # youtube | coraal-buckeye | twitter | interview\n",
    "\n",
    "FILEPATH_KEY = None\n",
    "if DATASET == 'youtube':\n",
    "    FILEPATH_KEY = '05_youtube_features'\n",
    "elif DATASET == 'coraal-buckeye':\n",
    "    FILEPATH_KEY = '05_buckeye_corall_features'\n",
    "elif DATASET == 'twitter':\n",
    "    FILEPATH_KEY = '05_twitter_features'\n",
    "else:\n",
    "    raise Exception('Dataset does not exists')\n",
    "\n",
    "data = data_loader.load_dataset(DATASET)\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == 'twitter':\n",
    "    data['race'] = data['group']\n",
    "else:\n",
    "    aa_or_wh = lambda x: 'aa' if 'Black' in x else 'wh'\n",
    "    data['race'] = data.group.apply(aa_or_wh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LIWC VARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc_parser = Liwc(filepaths['liwc_dict'])\n",
    "\n",
    "data['clean_text'] = data['text'].apply(lambda x: re.sub(\"[^\\w\\d'\\s]+\",'',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>perspective_score</th>\n",
       "      <th>flair_score</th>\n",
       "      <th>textblob_score</th>\n",
       "      <th>vader_score</th>\n",
       "      <th>detoxify_original_score</th>\n",
       "      <th>detoxify_unbiased_score</th>\n",
       "      <th>detoxify_multilingual_score</th>\n",
       "      <th>has_swearing</th>\n",
       "      <th>file</th>\n",
       "      <th>...</th>\n",
       "      <th>liwc_body</th>\n",
       "      <th>liwc_money</th>\n",
       "      <th>liwc_hear</th>\n",
       "      <th>liwc_friend</th>\n",
       "      <th>liwc_family</th>\n",
       "      <th>liwc_motion</th>\n",
       "      <th>liwc_sexual</th>\n",
       "      <th>liwc_we</th>\n",
       "      <th>liwc_relig</th>\n",
       "      <th>liwc_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user wat r u doin boy</td>\n",
       "      <td>0.037538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048113</td>\n",
       "      <td>0.014581</td>\n",
       "      <td>0.146005</td>\n",
       "      <td>False</td>\n",
       "      <td>aa_112.csv</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     text  perspective_score  flair_score  textblob_score  \\\n",
       "0  @user wat r u doin boy           0.037538          0.0             0.0   \n",
       "\n",
       "   vader_score  detoxify_original_score  detoxify_unbiased_score  \\\n",
       "0          0.0                 0.048113                 0.014581   \n",
       "\n",
       "   detoxify_multilingual_score  has_swearing        file  ... liwc_body  \\\n",
       "0                     0.146005         False  aa_112.csv  ...       0.0   \n",
       "\n",
       "  liwc_money liwc_hear  liwc_friend  liwc_family  liwc_motion  liwc_sexual  \\\n",
       "0        0.0       0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   liwc_we  liwc_relig  liwc_number  \n",
       "0      0.0         0.0          0.0  \n",
       "\n",
       "[1 rows x 86 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['liwc_count'] = data['clean_text'].apply(liwc_utils.liwc_sentence_parse, args=(liwc_parser,)) #aplica do liwc\n",
    "liwc_count_df = data['liwc_count'].apply(pd.Series)\n",
    "liwc_count_df.columns = ['liwc_'+col for col in liwc_count_df.columns]\n",
    "data = pd.concat([data.drop(['liwc_count'], axis=1), liwc_count_df], axis=1)\n",
    "del liwc_count_df\n",
    "data = data.fillna(0) ## TODO: verificar\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AAE Terms Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms = [\n",
    "    # 'bad', \n",
    "    'bougie',\n",
    "    ['busting','out'], \n",
    "    'freak', \n",
    "    'fresh', \n",
    "    'homie', \n",
    "    'jones', \n",
    "    'mondo',\n",
    "    'rednecks',\n",
    "    'bopper',\n",
    "    'dime',\n",
    "\n",
    "    'honey',\n",
    "    ['hot','girl'],\n",
    "    'ma',\n",
    "    'shorty',\n",
    "    'wifey',\n",
    "\n",
    "    'balla',\n",
    "    'cat',\n",
    "    'cuz',\n",
    "    'dawg',\n",
    "    'dog',\n",
    "    'fool',\n",
    "    'homes',\n",
    "    'kinfolk',\n",
    "    'mark',\n",
    "    'money',\n",
    "    'player',\n",
    "    'playa',\n",
    "    'scrub',\n",
    "    'slick',\n",
    "\n",
    "    'benjis',\n",
    "    'benjamins',\n",
    "    'benjamin',\n",
    "    'cabbage',\n",
    "    'cheese',\n",
    "    'cream',\n",
    "    'duckets',\n",
    "    'franklins',\n",
    "    'franklin',\n",
    "    'paper',\n",
    "    'scrilla',\n",
    "\n",
    "    'bucks',\n",
    "    ['dead','presidents'],\n",
    "    'dime',\n",
    "    'paper',\n",
    "    ['cash','money'],\n",
    "    'dividends',\n",
    "    'dough',\n",
    "    'knot',\n",
    "    'bounce',\n",
    "    ['push','off'],\n",
    "    'murk',\n",
    "\n",
    "    ['playa','hatin'],\n",
    "    'hatin',\n",
    "    'hating',\n",
    "    ['hatin','on'],\n",
    "    ['balla','blockin'],\n",
    "\n",
    "    'feel',\n",
    "    [\"we're\",'here'],\n",
    "\n",
    "    ['push','up','on'],\n",
    "    ['get','wit'],\n",
    "    ['get','with'],\n",
    "    ['holler','at','that'],\n",
    "    'sweatin',\n",
    "\n",
    "    'sweating',\n",
    "    ['off','the','hook'],\n",
    "    ['off','the','chain'],\n",
    "    'krunk',\n",
    "    'banging',\n",
    "    ['too','stupid'],\n",
    "\n",
    "    'wanna',\n",
    "    'gotta',\n",
    "    'finna',\n",
    "    'bouta',\n",
    "    'tryna',\n",
    "    'gonna',\n",
    "]\n",
    "len(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['aae_terms_count'] = data.clean_text.str.split(' ').apply( lambda x: vocab_tools.count_terms_in_list(x,terms) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:03<00:00, 145.89it/s]\n"
     ]
    }
   ],
   "source": [
    "pos = data.text.progress_apply(vocab_tools.count_pos_classes, args=(nlp,) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_count_df = pos.apply(pd.Series)\n",
    "pos_count_df.columns = ['pos_'+col for col in pos_count_df.columns]\n",
    "pos_count_df = pos_count_df.fillna(0) # TODO: verificar isso\n",
    "# data = pd.concat([data, pos_count_df], axis=1)\n",
    "data = pd.concat([data, pos_count_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liwc categories: 73\n",
      "liwc columns: 73\n"
     ]
    }
   ],
   "source": [
    "#LIWC\n",
    "liwc_cols = [col for col in data.columns if 'liwc_' in col]\n",
    "print('liwc categories:',len(liwc_parser.categories.keys()))\n",
    "print('liwc columns:',len(liwc_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AAE Terms\n",
    "'aae_terms_count' in data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pos_ADJ', 'pos_NOUN', 'pos_INTJ', 'pos_ADV', 'pos_VERB', 'pos_ADP', 'pos_DET', 'pos_PUNCT', 'pos_SCONJ', 'pos_PRON', 'pos_AUX', 'pos_PROPN', 'pos_SYM', 'pos_CCONJ', 'pos_PART', 'pos_NUM', 'pos_X', 'pos_SPACE']\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "pos_cols = [col for col in data.columns if 'pos_' in col]\n",
    "print(pos_cols)\n",
    "print(len(pos_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# race \n",
    "'race' in data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y columns: ['perspective_score', 'flair_score', 'textblob_score', 'vader_score', 'detoxify_original_score', 'detoxify_unbiased_score', 'detoxify_multilingual_score']\n",
      "\n",
      "Number of regression features: 93\n",
      "\n",
      "Extra columns: ['text', 'file', 'has_swearing', 'group', 'clean_text']\n"
     ]
    }
   ],
   "source": [
    "y_cols = [col for col in data.columns if '_score' in col]\n",
    "print('Y columns:', y_cols)\n",
    "print()\n",
    "\n",
    "features = ['aae_terms_count'] + liwc_cols + pos_cols + ['race']\n",
    "print('Number of regression features:', len(features))\n",
    "print()\n",
    "\n",
    "print('Extra columns:',list(set(list(data.columns)) - set(features) - set(y_cols)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(filepaths[FILEPATH_KEY], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "716bd3ad375c41b9a51e5bdb0fea9e61f5f5b3cdf5599be47497d0ef2a02897b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
