{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-28 07:33:03.311370: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/oracle/instantclient_19_11:\n",
      "2022-01-28 07:33:03.311396: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import yaml\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme-resende/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "filepaths = yaml.load(open(\"../config/filepaths.yaml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Segmenter():\n",
    "    def __init__(self, model_path=\"../data/models/GloVe_w_LSTM\", max_tokens=200):\n",
    "        self.model = tf.keras.models.load_model(model_path)\n",
    "        self.max_tokens = max_tokens\n",
    "\n",
    "    def predict(self, X):\n",
    "            preds = [0]\n",
    "\n",
    "            X_splitted = X.split()\n",
    "            n_tokens = len(X_splitted)\n",
    "            i = 0\n",
    "            while i < n_tokens:\n",
    "                x_sliced = X_splitted[i:i + self.max_tokens]\n",
    "                x_to_pred = np.array([' '.join(x_sliced)])\n",
    "\n",
    "                partial_preds = self.model.predict(x_to_pred).numpy().reshape(1,-1)\n",
    "                partial_preds = (partial_preds > 0.5).astype(int)\n",
    "\n",
    "                punctuations = np.argwhere(partial_preds == 1)\n",
    "                # Shift all index by 1\n",
    "                punctuations += 1\n",
    "                if punctuations.shape[0] == 0:\n",
    "                    preds += [n_tokens]\n",
    "                    break\n",
    "                else:\n",
    "                    punctuations = punctuations[:, 1].reshape(-1)\n",
    "                    last_punctuation = punctuations[-1]\n",
    "\n",
    "                # Adds only the text until the last punctuation, because\n",
    "                # otherwise the next phrase will lack the entire context\n",
    "                punctuations += i\n",
    "                preds += punctuations.tolist()\n",
    "\n",
    "                i += last_punctuation\n",
    "\n",
    "            return preds\n",
    "    \n",
    "    def segment(self, X, punctuations):\n",
    "        sentences = []\n",
    "        \n",
    "        X_splitted = X.split()\n",
    "        for i in range(1, len(punctuations)):\n",
    "            left = punctuations[i-1]\n",
    "            right = punctuations[i]\n",
    "            \n",
    "            sentences.append(' '.join(X_splitted[left:right]))\n",
    "        \n",
    "        return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-28 07:33:06.258976: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-01-28 07:33:06.258994: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (kunumi): /proc/driver/nvidia/version does not exist\n",
      "2022-01-28 07:33:06.259145: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "segmenter = Segmenter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 552/552 [04:19<00:00,  2.12it/s]\n"
     ]
    }
   ],
   "source": [
    "filenames = [file.split(\"/\")[-1] for file in glob.glob(os.path.join(filepaths[\"preprocessed_data\"], \"*\"))]\n",
    "\n",
    "for filename in tqdm(filenames, total=len(filenames)):\n",
    "    with open(os.path.join(filepaths[\"preprocessed_data\"], filename)) as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    \n",
    "    sentences = segmenter.segment(text, segmenter.predict(text))\n",
    "    \n",
    "    df = pd.DataFrame(sentences, columns=[\"text\"])\n",
    "    df.to_csv(os.path.join(filepaths[\"model_based_segmentated_data\"], filename), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
