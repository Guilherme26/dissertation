{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Description\n",
    "\n",
    "This notebook calculates the toxicity score from each sentence in a subtitles' file. Finally, it persists the data in a DataFrame like output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --upgrade google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm\n",
    "from googleapiclient import discovery\n",
    "\n",
    "sys.path.append(\"../utils\")\n",
    "from toxicity_api_communication import get_toxicity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = yaml.load(open(\"../credentials.yaml\"))[\"perspective-api\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_toxicity_scores(credentials, input_path, output_path):\n",
    "    services = [\n",
    "        discovery.build(\n",
    "            \"commentanalyzer\",\n",
    "            \"v1alpha1\",\n",
    "            developerKey=value,\n",
    "            discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
    "            static_discovery=False,\n",
    "        ) for _, value in credentials.items()\n",
    "    ]\n",
    "\n",
    "    n_services = len(services)\n",
    "    filenames = [file.split(\"/\")[-1] for file in glob.glob(os.path.join(input_path, \"*\"))]\n",
    "\n",
    "    for filename in tqdm(filenames, total=len(filenames)):\n",
    "        df_sentences = pd.read_csv(os.path.join(input_path, filename))\n",
    "        for i, row in df_sentences.iterrows():\n",
    "            df_sentences.loc[i, \"score\"] = get_toxicity_score(services[i % n_services], row.text)\n",
    "\n",
    "            if (i % n_services) == 0:\n",
    "                time.sleep(1)\n",
    "\n",
    "        df_sentences.to_csv(os.path.join(output_path, filename), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_toxicity_scores(\n",
    "    credentials,\n",
    "    \"../data/02_segmented/fixed_size_context/without_curse_words\",\n",
    "    \"../data/03_scored/without_curse_words\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
