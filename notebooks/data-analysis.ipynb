{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']  = (3.33, 5.5)\n",
    "plt.rcParams['axes.labelsize']  = 16\n",
    "plt.rcParams['axes.titlesize']  = 18\n",
    "plt.rcParams['legend.fontsize'] = 16\n",
    "plt.rcParams['xtick.labelsize'] = 16\n",
    "plt.rcParams['ytick.labelsize'] = 16\n",
    "plt.rcParams['lines.linewidth'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = \"../data/00_raw\"\n",
    "filenames = os.listdir(pwd)\n",
    "\n",
    "PERSPECTIVE_CHAR_LIMIT = 3000\n",
    "n_small_corpus = 0\n",
    "n_curse_words = 0\n",
    "\n",
    "for file in filenames:\n",
    "    with open(os.path.join(pwd, file)) as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    if len(content) <= PERSPECTIVE_CHAR_LIMIT:\n",
    "        n_small_corpus += 1\n",
    "    \n",
    "    n_curse_words += len(re.findall(\"\\[ __ \\]+\", content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_files = len(filenames)\n",
    "\n",
    "print(\"Basic Statistics\")\n",
    "print(\"----------------\")\n",
    "print(f\"  - Percentage of data with less than 5000 characters is {n_small_corpus/n_files*100:0.2f}%\")\n",
    "print(f\"  - Average number of curse words is {n_curse_words/n_files:0.2f} per file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_download_info = pd.read_csv(\"../data/download_descriptions.csv\")\n",
    "\n",
    "print(\"Basic Statistics\")\n",
    "print(\"----------------\")\n",
    "print(f\"  - There are {df_download_info.movie.nunique()} different movies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = \"../data/03_scored/without_curse_words\"\n",
    "filenames = os.listdir(pwd)\n",
    "\n",
    "print(f\"  - There are {len(filenames)} different review videos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = \"../data/01_preprocessed/without_curse_words\"\n",
    "filenames = os.listdir(pwd)\n",
    "\n",
    "corpus_sizes = []\n",
    "for file in filenames:\n",
    "    with open(os.path.join(pwd, file)) as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    corpus_sizes.append(len(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(12,8))\n",
    "plt.hist(corpus_sizes, bins=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(9,7))\n",
    "plt.boxplot(corpus_sizes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/download_descriptions.csv\")\n",
    "\n",
    "data = df.groupby(\"group\").movie.count()\n",
    "\n",
    "plt.subplots(figsize=(12,8))\n",
    "plt.bar(data.index, data.values/df.shape[0])\n",
    "plt.title(\"Group Proportion\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_to_content = {}\n",
    "\n",
    "pwd = \"../data/03_scored/without_curse_words\"\n",
    "df = pd.read_csv(\"../data/download_descriptions.csv\")\n",
    "for group in df.group.unique():\n",
    "    dfs = []\n",
    "    for _, row in df[df.group == group].iterrows():\n",
    "        video_id_and_channel = row[\"url\"].split(\"v=\")[1]\n",
    "        video_id = video_id_and_channel.split(\"&\")[0]\n",
    "\n",
    "        try:\n",
    "            dfs.append(pd.read_csv(os.path.join(pwd, video_id)))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    df_group = pd.concat(dfs)\n",
    "    \n",
    "    df_group = df_group.sort_values(by=\"score\", ascending=False)[:100]\n",
    "    group_to_content[group] = ' '.join(df_group.text.values)\n",
    "    \n",
    "    del dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../data/imgs\"\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10,6))\n",
    "\n",
    "for i, (group, content) in enumerate(group_to_content.items()):\n",
    "    wordcloud = WordCloud(\n",
    "        stopwords=stopwords.words(\"english\"),\n",
    "        background_color=\"white\",\n",
    "        width=1600, height=800\n",
    "    ).generate(content)\n",
    "\n",
    "    axs[i//2, i%2].imshow(wordcloud, interpolation='bilinear')\n",
    "    axs[i//2, i%2].set_title(f\"{group}\")\n",
    "    axs[i//2, i%2].set_axis_off()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_path, \"wordclouds.pdf\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_to_content = {}\n",
    "curse_words = json.load(open(\"../data/bad_words_scored.json\"))\n",
    "curse_words = [key for key, value in curse_words.items() if value > 0.2]\n",
    "\n",
    "pwd = \"../data/03_scored/with_curse_words\"\n",
    "df = pd.read_csv(\"../data/download_descriptions.csv\")\n",
    "for group in df.group.unique():\n",
    "    dfs = []\n",
    "    for _, row in df[df.group == group].iterrows():\n",
    "        video_id_and_channel = row[\"url\"].split(\"v=\")[1]\n",
    "        video_id = video_id_and_channel.split(\"&\")[0]\n",
    "\n",
    "        try:\n",
    "            dfs.append(pd.read_csv(os.path.join(pwd, video_id)))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    df_group = pd.concat(dfs)\n",
    "    group_to_content[group] = ' '.join(df_group.text.values)\n",
    "    \n",
    "    del dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curse_words = open(\"../data/bad_words.txt\").read().split()\n",
    "n_curse_per_group = {}\n",
    "\n",
    "for group, content in group_to_content.items():\n",
    "    for word in content.split():\n",
    "        if word in curse_words:\n",
    "            n_curse_per_group[group] = n_curse_per_group.get(group, 0) + 1\n",
    "    \n",
    "    n_curse_per_group[group] = n_curse_per_group[group]/len(content.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(n_curse_per_group.items(), key=lambda item: item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
