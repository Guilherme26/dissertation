{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Description\n",
    "\n",
    "This notebook calculates the toxicity score for every curse word from a file, gets the curse word with the median toxicity score (according to Perpective), and replace every curse word identifier on the subtitles by the median word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import yaml\n",
    "import time\n",
    "import json\n",
    "import sys\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "from googleapiclient import discovery\n",
    "\n",
    "sys.path.append(\"../utils\")\n",
    "from toxicity_api_communication import get_toxicity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_63366/291677732.py:1: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  filepaths = yaml.load(open(\"../config/filepaths.yaml\"))\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../credentials.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m filepaths \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../config/filepaths.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m credentials \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../credentials.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperspective-api\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      4\u001b[0m service \u001b[38;5;241m=\u001b[39m discovery\u001b[38;5;241m.\u001b[39mbuild(\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommentanalyzer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv1alpha1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     static_discovery\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../credentials.yaml'"
     ]
    }
   ],
   "source": [
    "filepaths = yaml.load(open(\"../config/filepaths.yaml\"))\n",
    "credentials = yaml.load(open(\"../credentials.yaml\"))[\"perspective-api\"]\n",
    "\n",
    "service = discovery.build(\n",
    "    \"commentanalyzer\",\n",
    "    \"v1alpha1\",\n",
    "    developerKey=credentials[\"key-1\"],\n",
    "    discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
    "    static_discovery=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the Toxicity for Every Curse Word\n",
    "\n",
    "Calculate the toxicity score for every curse word in the file referenced [here](https://www.cs.cmu.edu/~biglou/resources/) built by [Luis von Ahn](https://www.cs.cmu.edu/~biglou/)'s Research Group.\n",
    "\n",
    "We need to take into consideration that some words do not present considerable toxicity scores. For example, \"nook\", \"dahmer\", \"palesimian\" both are considered to be curse words, however, have less than 5.0 toxicity scores, whereas muslim (18.99), medication (18.6), interracial (18.39), and atheist (15.83) are substantially more toxic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'False'\n"
     ]
    }
   ],
   "source": [
    "%%script False\n",
    "\n",
    "with open(filepaths[\"bad_words_raw\"]) as f:\n",
    "    curse_words = f.read().split()\n",
    "\n",
    "curse_words_score = {}\n",
    "for word in tqdm(curse_words, total=len(curse_words)):\n",
    "    toxicity = get_toxicity_score(service, word)\n",
    "    \n",
    "    if toxicity is not None:\n",
    "        curse_words_score[word] = toxicity\n",
    "\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Persist the scored curse words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'False'\n"
     ]
    }
   ],
   "source": [
    "%%script False\n",
    "\n",
    "with open(filepaths[\"bad_words_scored\"]) as f:\n",
    "    json.dump(dict(curse_words_score), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove irrelevant words that should not be considered curse words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'False'\n"
     ]
    }
   ],
   "source": [
    "%%script False\n",
    "\n",
    "filtered_curse_words_score = {}\n",
    "for key, value in curse_words_score.items():\n",
    "    if value > 0.2:\n",
    "        filtered_curse_words_score[key] = value\n",
    "\n",
    "curse_words_score = filtered_curse_words_score\n",
    "del filtered_curse_words_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the median curse word index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'False'\n"
     ]
    }
   ],
   "source": [
    "%%script False\n",
    "\n",
    "curse_words_score = sorted(curse_words_score.items(), key=lambda item: item[1])\n",
    "\n",
    "median_idx = len(curse_words_score) // 2\n",
    "median_curse_word, median_score = curse_words_score[median_idx]\n",
    "\n",
    "print(f\"The median word is `{median_curse_word}` with a toxicity score of {median_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_tokens(input_path, output_path):\n",
    "    filenames = [file.split(\"/\")[-1] for file in glob.glob(os.path.join(input_path, \"*\"))]\n",
    "\n",
    "    for filename in tqdm(filenames, total=len(filenames)):\n",
    "        with open(os.path.join(input_path, filename)) as file:\n",
    "            text = file.read()\n",
    "\n",
    "        if re.search(\"\\[ __ \\]+\", text) is not None:\n",
    "            continue\n",
    "            \n",
    "        text = text.replace(\"[Music]\", '')\n",
    "\n",
    "        with open(os.path.join(output_path, filename), 'w') as file:\n",
    "            file.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Remove files with censured curse words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 634/634 [00:00<00:00, 7939.80it/s]\n"
     ]
    }
   ],
   "source": [
    "replace_tokens(filepaths[\"raw_data\"], filepaths[\"preprocessed_data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
